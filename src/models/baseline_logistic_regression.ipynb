{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "colab_type": "text",
        "id": "view-in-github"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mchami02/Road-Segmentation-Comp/blob/adam-workplace2/Baseline_logistic_regression.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "LixKL3uE6Wbi"
      },
      "outputs": [],
      "source": [
        "import math\n",
        "import os\n",
        "import re\n",
        "import cv2\n",
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "from glob import glob\n",
        "from random import sample\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import f1_score\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_ahf3qfh6116"
      },
      "outputs": [],
      "source": [
        "PATCH_SIZE = 16  # pixels per side of square patches\n",
        "VAL_SIZE = 10  # size of the validation set (number of images)\n",
        "CUTOFF = 0.25  # minimum average brightness for a mask patch to be classified as containing road"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "79lrEeBd65O9"
      },
      "outputs": [],
      "source": [
        "ROOT_PATH = \"/content/drive/MyDrive/Road-Segmentation-Comp/ethz-cil-road-segmentation-2024\""
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "gP3zXxgt6-tX"
      },
      "outputs": [],
      "source": [
        "def load_all_from_path(path):\n",
        "    # loads all HxW .pngs contained in path as a 4D np.array of shape (n_images, H, W, 3)\n",
        "    # images are loaded as floats with values in the interval [0., 1.]\n",
        "    return np.stack([np.array(Image.open(f)) for f in sorted(glob(path + '/*.png'))]).astype(np.float32) / 255.\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {
        "id": "eWUQ3LNt7DM6"
      },
      "outputs": [],
      "source": [
        "images = load_all_from_path(os.path.join(ROOT_PATH, 'training', 'images'))[:, :, :, :3]\n",
        "masks = load_all_from_path(os.path.join(ROOT_PATH, 'training', 'groundtruth'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {
        "id": "O9utpwBm7FIM"
      },
      "outputs": [],
      "source": [
        "train_images, val_images, train_masks, val_masks = train_test_split(\n",
        "    images, masks, test_size=0.2, random_state=42\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {
        "id": "2J2cFPlm_Rk7"
      },
      "outputs": [],
      "source": [
        "def image_to_patches(images, masks=None):\n",
        "    # takes in a 4D np.array containing images and (optionally) a 4D np.array containing the segmentation masks\n",
        "    # returns a 4D np.array with an ordered sequence of patches extracted from the image and (optionally) a np.array containing labels\n",
        "    n_images = images.shape[0]  # number of images\n",
        "    h, w = images.shape[1:3]  # shape of images\n",
        "    assert (h % PATCH_SIZE) + (w % PATCH_SIZE) == 0  # make sure images can be patched exactly\n",
        "\n",
        "    images = images[:,:,:,:3]\n",
        "\n",
        "    h_patches = h // PATCH_SIZE\n",
        "    w_patches = w // PATCH_SIZE\n",
        "\n",
        "    patches = images.reshape((n_images, h_patches, PATCH_SIZE, w_patches, PATCH_SIZE, -1))\n",
        "    patches = np.moveaxis(patches, 2, 3)\n",
        "    patches = patches.reshape(-1, PATCH_SIZE, PATCH_SIZE, 3)\n",
        "    if masks is None:\n",
        "        return patches\n",
        "\n",
        "    masks = masks.reshape((n_images, h_patches, PATCH_SIZE, w_patches, PATCH_SIZE, -1))\n",
        "    masks = np.moveaxis(masks, 2, 3)\n",
        "    labels = np.mean(masks, (-1, -2, -3)) > CUTOFF  # compute labels\n",
        "    labels = labels.reshape(-1).astype(np.float32)\n",
        "    return patches, labels"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "XSPEjtt7_VYs"
      },
      "outputs": [],
      "source": [
        "# extract all patches\n",
        "train_patches, train_labels = image_to_patches(train_images, train_masks)\n",
        "val_patches, val_labels = image_to_patches(val_images, val_masks)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2HOWVQ46_buF"
      },
      "source": [
        "Baseline Model 1: Logistic Regression"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mTOKSWpz_fSt",
        "outputId": "e857de18-3009-4991-f07e-73ccf3a042fa"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Training accuracy: 0.6021982608695652\n",
            "Validation accuracy: 0.5971862068965518\n"
          ]
        }
      ],
      "source": [
        "def extract_features(x):\n",
        "    return np.concatenate([np.mean(x, (-2, -3)), np.var(x, (-2,-3))], axis=-1)\n",
        "\n",
        "train_patches, train_labels = image_to_patches(train_images, train_masks)\n",
        "val_patches, val_labels = image_to_patches(val_images, val_masks)\n",
        "\n",
        "x_train = extract_features(train_patches)\n",
        "x_val = extract_features(val_patches)\n",
        "clf = LogisticRegression(class_weight='balanced').fit(x_train, train_labels)\n",
        "print(f'Training accuracy: {clf.score(x_train, train_labels)}')\n",
        "print(f'Validation accuracy: {clf.score(x_val, val_labels)}')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xl_PXibeAEbI",
        "outputId": "30a8da6c-71c8-4ff0-c06b-709a6f4c4bbd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Validation F1-score: 0.46304331837905416\n"
          ]
        }
      ],
      "source": [
        "y_pred = clf.predict(x_val)\n",
        "f1 = f1_score(val_labels, y_pred)\n",
        "print(f'Validation F1-score: {f1}')"
      ]
    }
  ],
  "metadata": {
    "colab": {
      "authorship_tag": "ABX9TyMNJ9T0WzmXOqRfpH4UA1W2",
      "include_colab_link": true,
      "mount_file_id": "1J8v0BP43Vq_2LierKlkzl-CqJJKUECcR",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python",
      "version": "3.12.2"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
