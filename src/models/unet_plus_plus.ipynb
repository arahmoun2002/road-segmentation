{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "f45d32dd",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3ab5fea3",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2024-07-31 12:12:18.708110: I tensorflow/core/util/port.cc:153] oneDNN custom operations are on. You may see slightly different numerical results due to floating-point round-off errors from different computation orders. To turn them off, set the environment variable `TF_ENABLE_ONEDNN_OPTS=0`.\n",
      "2024-07-31 12:12:19.230710: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:485] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "2024-07-31 12:12:19.380899: E external/local_xla/xla/stream_executor/cuda/cuda_dnn.cc:8454] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "2024-07-31 12:12:19.431073: E external/local_xla/xla/stream_executor/cuda/cuda_blas.cc:1452] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "2024-07-31 12:12:19.742198: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: AVX2 AVX_VNNI FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n",
      "2024-07-31 12:12:22.647332: W tensorflow/compiler/tf2tensorrt/utils/py_utils.cc:38] TF-TRT Warning: Could not find TensorRT\n"
     ]
    },
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'segmentation_models_pytorch'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[1], line 9\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdata\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DataLoader, TensorDataset\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msegmentation_models_pytorch\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01msmp\u001b[39;00m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msegmentation_models_pytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m IoU, Precision, Recall\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01msegmentation_models_pytorch\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mlosses\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m DiceLoss\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'segmentation_models_pytorch'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "sys.path.insert(0, '../')\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.models import load_model\n",
    "\n",
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "import segmentation_models_pytorch as smp\n",
    "from segmentation_models_pytorch.utils.metrics import IoU, Precision, Recall\n",
    "from segmentation_models_pytorch.utils.losses import DiceLoss\n",
    "\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import cv2\n",
    "from skimage import util\n",
    "from pathlib import Path\n",
    "from skimage import util, filters, morphology\n",
    "\n",
    "from preprocessing.preprocess_data import get_preprocessed_data, TRAIN_PATH, _read_image\n",
    "from mask_to_submission import *\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0e91df9",
   "metadata": {},
   "source": [
    "### Loading the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f66157fb-b134-4452-b9d3-a99153b2a479",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'get_preprocessed_data' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m val_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0.2\u001b[39m\n\u001b[0;32m----> 3\u001b[0m (X_train, Y_train), (X_val, Y_val) \u001b[38;5;241m=\u001b[39m \u001b[43mget_preprocessed_data\u001b[49m(path\u001b[38;5;241m=\u001b[39mTRAIN_PATH, val_size\u001b[38;5;241m=\u001b[39mval_size)\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mTraining data shapes: X_train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Y_train: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mY_train\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mValidation data shapes: X_val: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mX_val\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m, Y_val: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mY_val\u001b[38;5;241m.\u001b[39mshape\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m'\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'get_preprocessed_data' is not defined"
     ]
    }
   ],
   "source": [
    "val_size = 0.2\n",
    "\n",
    "(X_train, Y_train), (X_val, Y_val) = get_preprocessed_data(path=TRAIN_PATH, val_size=val_size)\n",
    "\n",
    "print(f'Training data shapes: X_train: {X_train.shape}, Y_train: {Y_train.shape}')\n",
    "print(f'Validation data shapes: X_val: {X_val.shape}, Y_val: {Y_val.shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e36505c-5e85-4e77-bd6e-f1a372504eb4",
   "metadata": {},
   "source": [
    "#### Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f83af4a-3603-4351-bbd4-4f7b8f1baa86",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = smp.UnetPlusPlus(\n",
    "        encoder_name=\"resnet34\",\n",
    "        encoder_weights='imagenet',\n",
    "        classes=1, \n",
    "        activation='sigmoid'  \n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "ee7c2330-b7fb-4619-a586-94e20c7bd30d",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Define the padding function\n",
    "def pad_to_32(image):\n",
    "    h, w = image.shape[:2]\n",
    "    new_h, new_w = (h + 31) // 32 * 32, (w + 31) // 32 * 32\n",
    "    pad_h, pad_w = new_h - h, new_w - w\n",
    "    image = np.pad(image, ((0, pad_h), (0, pad_w), (0, 0)), mode='constant', constant_values=0)\n",
    "    return image\n",
    "\n",
    "# Apply padding to the dataset\n",
    "def pad_images(images):\n",
    "    padded_images = [pad_to_32(img) for img in images]\n",
    "    return padded_images\n",
    "\n",
    "# Pad the training and validation images\n",
    "X_train_padded = pad_images(X_train)\n",
    "Y_train_padded = pad_images(Y_train)\n",
    "X_val_padded = pad_images(X_val)\n",
    "Y_val_padded = pad_images(Y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "57d61704-dd42-424f-962e-3c6da902cf81",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/var/folders/tg/k5r1c31d7v9g56r0919lqbz40000gn/T/ipykernel_3478/2500452614.py:2: UserWarning: Creating a tensor from a list of numpy.ndarrays is extremely slow. Please consider converting the list to a single numpy.ndarray with numpy.array() before converting to a tensor. (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_new.cpp:277.)\n",
      "  X_train_tensor = torch.tensor(X_train_padded, dtype=torch.float32).permute(0, 3, 1, 2)\n"
     ]
    }
   ],
   "source": [
    "# Convert data to PyTorch tensors\n",
    "X_train_tensor = torch.tensor(X_train_padded, dtype=torch.float32).permute(0, 3, 1, 2)\n",
    "Y_train_tensor = torch.tensor(Y_train_padded, dtype=torch.float32).permute(0, 3, 1, 2)\n",
    "X_val_tensor = torch.tensor(X_val_padded, dtype=torch.float32).permute(0, 3, 1, 2)\n",
    "Y_val_tensor = torch.tensor(Y_val_padded, dtype=torch.float32).permute(0, 3, 1, 2)\n",
    "\n",
    "# Create TensorDataset and DataLoader\n",
    "train_dataset = TensorDataset(X_train_tensor, Y_train_tensor)\n",
    "val_dataset = TensorDataset(X_val_tensor, Y_val_tensor)\n",
    "train_loader = DataLoader(train_dataset, batch_size=16, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=16, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "944e4f89-e45f-4d7c-a40c-4a8515ce8959",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Epoch: 0\n",
      "train: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [40:16<00:00, 36.07s/it, dice_loss - 0.6157, iou_score - 0.3292, precision - 0.3621, recall - 0.7675]\n",
      "valid: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [03:15<00:00, 11.50s/it, dice_loss - 0.5292, iou_score - 0.4164, precision - 0.4488, recall - 0.8535]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 1\n",
      "train: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [40:23<00:00, 36.16s/it, dice_loss - 0.4899, iou_score - 0.4612, precision - 0.5031, recall - 0.8511]\n",
      "valid: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [03:11<00:00, 11.28s/it, dice_loss - 0.4681, iou_score - 0.486, precision - 0.5874, recall - 0.7416]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 2\n",
      "train: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [42:05<00:00, 37.70s/it, dice_loss - 0.424, iou_score - 0.5383, precision - 0.589, recall - 0.8655]\n",
      "valid: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [03:12<00:00, 11.33s/it, dice_loss - 0.4345, iou_score - 0.5013, precision - 0.5806, recall - 0.7876]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 3\n",
      "train: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 67/67 [1:23:20<00:00, 74.63s/it, dice_loss - 0.3701, iou_score - 0.5941, precision - 0.6479, recall - 0.8796]\n",
      "valid: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [03:11<00:00, 11.24s/it, dice_loss - 0.4072, iou_score - 0.5175, precision - 0.6185, recall - 0.7623]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 4\n",
      "train: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [53:43<00:00, 48.11s/it, dice_loss - 0.3233, iou_score - 0.6387, precision - 0.6999, recall - 0.8824]\n",
      "valid: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [03:10<00:00, 11.18s/it, dice_loss - 0.3826, iou_score - 0.5285, precision - 0.6541, recall - 0.7357]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 5\n",
      "train: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 67/67 [1:03:48<00:00, 57.13s/it, dice_loss - 0.2886, iou_score - 0.6664, precision - 0.7313, recall - 0.8846]\n",
      "valid: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [03:11<00:00, 11.28s/it, dice_loss - 0.3757, iou_score - 0.519, precision - 0.6147, recall - 0.7708]\n",
      "\n",
      "Epoch: 6\n",
      "train: 100%|███████████████████████████████████████████████████████████████████████████████████████████████| 67/67 [40:41<00:00, 36.44s/it, dice_loss - 0.258, iou_score - 0.6907, precision - 0.759, recall - 0.8865]\n",
      "valid: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [03:10<00:00, 11.22s/it, dice_loss - 0.354, iou_score - 0.5362, precision - 0.6629, recall - 0.7386]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 7\n",
      "train: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 67/67 [2:03:49<00:00, 110.89s/it, dice_loss - 0.2278, iou_score - 0.7199, precision - 0.7928, recall - 0.8889]\n",
      "valid: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [02:57<00:00, 10.45s/it, dice_loss - 0.3432, iou_score - 0.5401, precision - 0.6947, recall - 0.7092]\n",
      "Model saved!\n",
      "\n",
      "Epoch: 8\n",
      "train: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 67/67 [2:35:05<00:00, 138.89s/it, dice_loss - 0.2049, iou_score - 0.7394, precision - 0.8125, recall - 0.8934]\n",
      "valid: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [03:00<00:00, 10.62s/it, dice_loss - 0.3459, iou_score - 0.5289, precision - 0.7158, recall - 0.6707]\n",
      "\n",
      "Epoch: 9\n",
      "train: 100%|██████████████████████████████████████████████████████████████████████████████████████████| 67/67 [3:38:37<00:00, 195.78s/it, dice_loss - 0.1885, iou_score - 0.7519, precision - 0.8289, recall - 0.8921]\n",
      "valid: 100%|██████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [03:00<00:00, 10.62s/it, dice_loss - 0.332, iou_score - 0.5382, precision - 0.7151, recall - 0.6867]\n",
      "\n",
      "Epoch: 10\n",
      "train: 100%|███████████████████████████████████████████████████████████████████████████████████████████| 67/67 [1:05:24<00:00, 58.57s/it, dice_loss - 0.1724, iou_score - 0.7662, precision - 0.8412, recall - 0.8976]\n",
      "valid: 100%|█████████████████████████████████████████████████████████████████████████████████████████████| 17/17 [03:12<00:00, 11.30s/it, dice_loss - 0.3289, iou_score - 0.5352, precision - 0.7201, recall - 0.6771]\n",
      "\n",
      "Epoch: 11\n",
      "train:  76%|██████████████████████████████████████████████████████████████████████▊                      | 51/67 [44:15<10:38, 39.93s/it, dice_loss - 0.1579, iou_score - 0.7816, precision - 0.8556, recall - 0.9015]"
     ]
    }
   ],
   "source": [
    "EPOCHS = 30\n",
    "DEVICE = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "loss = DiceLoss()\n",
    "\n",
    "metrics = [\n",
    "    IoU(threshold=0.5),\n",
    "    Precision(threshold=0.5),\n",
    "    Recall(threshold=0.5),\n",
    "    Fscore(threshold=0.5),\n",
    "]\n",
    "\n",
    "optimizer = torch.optim.Adam([ \n",
    "    dict(params=model.parameters(), lr=0.00008),\n",
    "])\n",
    "\n",
    "lr_scheduler = torch.optim.lr_scheduler.CosineAnnealingWarmRestarts(\n",
    "    optimizer, T_0=1, T_mult=2, eta_min=5e-5,\n",
    ")\n",
    "\n",
    "train_epoch = smp.utils.train.TrainEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    optimizer=optimizer,\n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "valid_epoch = smp.utils.train.ValidEpoch(\n",
    "    model, \n",
    "    loss=loss, \n",
    "    metrics=metrics, \n",
    "    device=DEVICE,\n",
    "    verbose=True,\n",
    ")\n",
    "\n",
    "best_iou_score = 0.0\n",
    "train_logs_list, valid_logs_list = [], []\n",
    "for i in range(0, EPOCHS):\n",
    "    # Perform training & validation\n",
    "    print('\\nEpoch: {}'.format(i))\n",
    "    train_logs = train_epoch.run(train_loader)\n",
    "    valid_logs = valid_epoch.run(val_loader)\n",
    "    train_logs_list.append(train_logs)\n",
    "    valid_logs_list.append(valid_logs)\n",
    "    # Save model if a better val IoU score is obtained\n",
    "    if best_iou_score < valid_logs['iou_score']:\n",
    "        best_iou_score = valid_logs['iou_score']\n",
    "        torch.save(model, './modelu++.pth')\n",
    "        print('Model saved!')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "95f0782d",
   "metadata": {},
   "source": [
    "### Predict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "64e0291b-5662-4046-b021-e1627de1e252",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# Function to visualize the predictions\n",
    "def visualize_predictions(model, val_loader, device, num_images=5):\n",
    "    \"\"\"Visualizes the predictions made by a given model on a validation dataset.\n",
    "\n",
    "    Args:\n",
    "        model (torch.nn.Module): The model to visualize predictions for.\n",
    "        val_loader (torch.utils.data.DataLoader): The validation data loader.\n",
    "        device (torch.device): The device to run the model on.\n",
    "        num_images (int, optional): The number of images to visualize. Defaults to 5.\n",
    "    \"\"\"\n",
    "    model.eval()  # Set model to evaluation mode\n",
    "    fig, axes = plt.subplots(num_images, 3, figsize=(15, num_images * 5))\n",
    "    \n",
    "    with torch.no_grad():  # Disable gradient computation\n",
    "        for i, (images, masks) in enumerate(val_loader):\n",
    "            images = images.to(device)\n",
    "            print(images.shape)\n",
    "            masks = masks.to(device)\n",
    "            predictions = model(images)\n",
    "            \n",
    "            for j in range(min(num_images, images.size(0))):\n",
    "                image = images[j].cpu().permute(1, 2, 0).numpy()\n",
    "                print(image.shape)\n",
    "\n",
    "                mask = masks[j].cpu().permute(1, 2, 0).numpy()\n",
    "                prediction = predictions[j].cpu().permute(1, 2, 0).numpy()\n",
    "                \n",
    "                # Plot original image\n",
    "                axes[j, 0].imshow(image)\n",
    "                axes[j, 0].set_title(\"Original Image\")\n",
    "                axes[j, 0].axis('off')\n",
    "                \n",
    "                # Plot ground truth mask\n",
    "                axes[j, 1].imshow(mask, cmap='gray')\n",
    "                axes[j, 1].set_title(\"Ground Truth Mask\")\n",
    "                axes[j, 1].axis('off')\n",
    "                \n",
    "                # Plot predicted mask\n",
    "                axes[j, 2].imshow(prediction, cmap='gray')\n",
    "                axes[j, 2].set_title(\"Predicted Mask\")\n",
    "                axes[j, 2].axis('off')\n",
    "            \n",
    "            if i + 1 >= num_images // images.size(0):\n",
    "                break\n",
    "\n",
    "# Visualize the predictions\n",
    "best_model = torch.load('./best_model.pth', map_location=DEVICE)\n",
    "visualize_predictions(best_model, val_loader, DEVICE, num_images=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f8695dd-9471-47f0-8598-24b1ba56b1b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/eliotullmo/opt/anaconda3/lib/python3.9/site-packages/pandas/core/computation/expressions.py:21: UserWarning: Pandas requires version '2.8.4' or newer of 'numexpr' (version '2.8.3' currently installed).\n",
      "  from pandas.core.computation.check import NUMEXPR_INSTALLED\n",
      "/Users/eliotullmo/opt/anaconda3/lib/python3.9/site-packages/pandas/core/arrays/masked.py:60: UserWarning: Pandas requires version '1.3.6' or newer of 'bottleneck' (version '1.3.5' currently installed).\n",
      "  from pandas.core import (\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "predicting\n"
     ]
    }
   ],
   "source": [
    "# if you dont have memory issues, you can not predict in batches\n",
    "def get_preprocessed_test_data(path: str):\n",
    "    \"\"\"Load and preprocess the test data.\n",
    "\n",
    "    Args:\n",
    "        path (str): The path to the test data.\n",
    "\n",
    "    Returns:\n",
    "        np.ndarray: The preprocessed test data.\n",
    "    \"\"\"\n",
    "    test_x_files = sorted([filename for filename in os.listdir(path) if filename.endswith('.png')])\n",
    "    test_x = np.array([_read_image(f'{path}/{filename}') for filename in test_x_files])\n",
    "    return test_x, test_x_files\n",
    "\n",
    "# Assuming DiceLoss is defined elsewhere\n",
    "dice_loss = DiceLoss()\n",
    "\n",
    "model = best_model\n",
    "model = model.to(DEVICE)\n",
    "model.eval()\n",
    "\n",
    "X_test, X_test_files = get_preprocessed_test_data(path='ethz-cil-road-segmentation-2024/test/images')\n",
    "\n",
    "X_test = np.array(X_test)\n",
    "X_test = pad_images(X_test)\n",
    "\n",
    "\n",
    "X_test = np.transpose(X_test, (0, 3, 1, 2))\n",
    "X_test = torch.from_numpy(X_test)\n",
    "X_test = X_test.to(DEVICE)\n",
    "\n",
    "if torch.cuda.device_count() > 1:\n",
    "    print(f\"Using {torch.cuda.device_count()} GPUs for parallel processing\")\n",
    "    model = torch.nn.DataParallel(model)\n",
    "print(\"predicting\")\n",
    "# Make predictions\n",
    "y_pred = model(X_test)\n",
    "\n",
    "# Ensure the predictions are of shape (height, width) before converting to images\n",
    "y_pred = (y_pred > 0.5).astype(np.uint8).squeeze(axis=-1)  # Squeeze the last dimension if necessary\n",
    "\n",
    "pred_images = [Image.fromarray((y_pred[i] * 255)).resize((400, 400)) for i in range(y_pred.shape[0])]\n",
    "\n",
    "output_path = 'outputs2'\n",
    "os.makedirs(output_path, exist_ok=True)  # Ensure the output directory exists\n",
    "\n",
    "# Save all images in the output_path directory\n",
    "for i, img in enumerate(pred_images):\n",
    "    img.save(f'{output_path}/pred_{X_test_files[i]}')\n",
    "\n",
    "print(\"Images have been successfully saved.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "070ba75c",
   "metadata": {},
   "source": [
    "### Post processing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b09583",
   "metadata": {},
   "outputs": [],
   "source": [
    "def th_li(image):\n",
    "    \"\"\"Apply Li thresholding.\"\"\"\n",
    "    threshold_value = filters.threshold_li(image)\n",
    "    binary_image = image > threshold_value\n",
    "    return binary_image.astype(np.uint8)\n",
    "\n",
    "def th_manual(image, manual_t):\n",
    "    \"\"\"Apply manual thresholding.\"\"\"\n",
    "    binary_image = image > (manual_t * 255)\n",
    "    return binary_image.astype(np.uint8)\n",
    "\n",
    "def morph_closing(image, filter_size=20):\n",
    "    \"\"\"Apply morphological closing.\"\"\"\n",
    "    selem = morphology.disk(filter_size)\n",
    "    closed_image = morphology.closing(image, selem)\n",
    "    return closed_image\n",
    "\n",
    "def morph_area_opening(image, area_size=400):\n",
    "    \"\"\"Apply morphological area opening.\"\"\"\n",
    "    opened_image = morphology.remove_small_objects(image.astype(bool), min_size=area_size)\n",
    "    return opened_image.astype(np.uint8)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da14bf2b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def postprocess_images(pred_images, filenames, output_path):\n",
    "    Path(output_path).mkdir(parents=True, exist_ok=True)\n",
    "    manual_t = 0.3\n",
    "\n",
    "    final_images = []\n",
    "    for i, im in enumerate(pred_images):\n",
    "        # Apply thresholding\n",
    "        im_li = th_li(im)\n",
    "        im_manual = th_manual(im, manual_t)\n",
    "\n",
    "        # Apply morphological operations\n",
    "        first = morph_closing(im_li, filter_size=6)\n",
    "        new_im = morph_area_opening(first, area_size=400)\n",
    "\n",
    "        new_im = np.expand_dims(new_im, axis=2)\n",
    "        name = output_path + \"pred_satimage_\" + str(filenames[i][14:17]) + \".png\"\n",
    "        cv2.imwrite(name, new_im * 255)  # Ensure image is saved correctly\n",
    "        final_images.append(new_im)\n",
    "        print(f\"Written to {name}\")\n",
    "    return final_images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9b8e5de2",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_predicted_images(path: str):\n",
    "    \"\"\"Load the predicted images from the specified path.\"\"\"\n",
    "    filenames = sorted([f for f in os.listdir(path) if f.endswith('.png')])\n",
    "    images = [cv2.imread(os.path.join(path, f), cv2.IMREAD_GRAYSCALE) for f in filenames]\n",
    "    return images, filenames\n",
    "\n",
    "predictions_path = 'insert'\n",
    "output_path = 'insert'\n",
    "\n",
    "pred_images, filenames = load_predicted_images(predictions_path)\n",
    "pred_images = [util.img_as_ubyte(im) for im in pred_images]\n",
    "\n",
    "postprocess_images(pred_images, filenames, output_path)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
