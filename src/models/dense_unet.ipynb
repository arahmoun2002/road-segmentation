{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "L4",
      "mount_file_id": "1YouVZa3p48SQyOrDGByDmoWj6goT2nn9",
      "authorship_tag": "ABX9TyM6mHsyAefc7Tjd15kON/AV",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mchami02/Road-Segmentation-Comp/blob/adam-workplace2/Dense_U_Net.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "import numpy as np\n",
        "from glob import glob\n",
        "from PIL import Image\n",
        "from sklearn.model_selection import train_test_split\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras.models import Model\n",
        "from tensorflow.keras.layers import Input, Conv2D, UpSampling2D, concatenate\n",
        "from tensorflow.keras.applications import DenseNet121\n",
        "from sklearn.metrics import f1_score\n",
        "import matplotlib.pyplot as plt\n",
        "import random"
      ],
      "metadata": {
        "id": "PbVUG7kAHxRb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Function to load and resize all images from a directory\n",
        "def load_all_from_path(path, target_size=(256, 256), convert_to_grayscale=False):\n",
        "    \"\"\"\n",
        "    Load and resize all images from the given directory.\n",
        "\n",
        "    Args:\n",
        "        path (str): Path to the directory containing images.\n",
        "        target_size (tuple): Desired size of the output images.\n",
        "        convert_to_grayscale (bool): If True, convert images to grayscale.\n",
        "\n",
        "    Returns:\n",
        "        np.ndarray: Array of images.\n",
        "    \"\"\"\n",
        "    images = []\n",
        "    for f in sorted(glob(os.path.join(path, '*.png'))):\n",
        "        img = Image.open(f)\n",
        "        if convert_to_grayscale:\n",
        "            img = img.convert('L')  # Convert to grayscale\n",
        "        else:\n",
        "            img = img.convert('RGB')\n",
        "        img = img.resize(target_size, Image.ANTIALIAS)\n",
        "        images.append(np.array(img))\n",
        "\n",
        "    images = np.stack(images).astype(np.float32) / 255.\n",
        "\n",
        "    if convert_to_grayscale:\n",
        "        images = np.expand_dims(images, axis=-1)  # Add channel dimension for grayscale\n",
        "\n",
        "    return images"
      ],
      "metadata": {
        "id": "PFsux-TJBZ4Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Load images and masks\n",
        "ROOT_PATH = \"/content/drive/MyDrive/Road-Segmentation-Comp/sampled/\"\n",
        "images = load_all_from_path(os.path.join(ROOT_PATH, 'images'))\n",
        "masks = load_all_from_path(os.path.join(ROOT_PATH, 'groundtruth'), convert_to_grayscale=True)\n",
        "\n",
        "# Ensure masks have the correct shape (adding a channel dimension if necessary)\n",
        "if len(masks.shape) == 3:  # If masks have shape (num_samples, height, width)\n",
        "    masks = np.expand_dims(masks, axis=-1)\n",
        "\n",
        "# Split data into training and validation sets\n",
        "train_images, val_images, train_masks, val_masks = train_test_split(images, masks, test_size=0.2, random_state=42)\n"
      ],
      "metadata": {
        "id": "BhqdviP8Ba6U"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to preprocess images and masks\n",
        "def preprocess(image, mask):\n",
        "    \"\"\"\n",
        "    Preprocess the images and masks: resize and ensure correct channels.\n",
        "\n",
        "    Args:\n",
        "        image (np.ndarray): Image to preprocess.\n",
        "        mask (np.ndarray): Mask to preprocess.\n",
        "\n",
        "    Returns:\n",
        "        Tuple of preprocessed image and mask.\n",
        "    \"\"\"\n",
        "    if image.shape[-1] == 4:\n",
        "        image = image[:, :, :3]\n",
        "\n",
        "    if len(mask.shape) == 2:\n",
        "        mask = tf.expand_dims(mask, axis=-1)\n",
        "\n",
        "    image = tf.image.resize(image, (256, 256))\n",
        "    mask = tf.image.resize(mask, (256, 256))\n",
        "    return image, mask\n",
        "\n",
        "# Load and preprocess dataset\n",
        "def load_dataset(images, masks):\n",
        "    \"\"\"\n",
        "    Create a TensorFlow dataset from images and masks.\n",
        "\n",
        "    Args:\n",
        "        images (np.ndarray): Array of images.\n",
        "        masks (np.ndarray): Array of masks.\n",
        "\n",
        "    Returns:\n",
        "        tf.data.Dataset: Preprocessed dataset.\n",
        "    \"\"\"\n",
        "    images = tf.convert_to_tensor(images, dtype=tf.float32)\n",
        "    masks = tf.convert_to_tensor(masks, dtype=tf.float32)\n",
        "\n",
        "    dataset = tf.data.Dataset.from_tensor_slices((images, masks))\n",
        "    dataset = dataset.map(lambda x, y: preprocess(x, y), num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
        "    dataset = dataset.batch(8).prefetch(tf.data.experimental.AUTOTUNE)\n",
        "    return dataset\n",
        "\n",
        "# Create datasets\n",
        "train_dataset = load_dataset(train_images, train_masks)\n",
        "val_dataset = load_dataset(val_images, val_masks)\n"
      ],
      "metadata": {
        "id": "lyBcvL7ZBeOI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "def unet_model(input_size=(256, 256, 3)):\n",
        "    \"\"\"\n",
        "    Build the U-Net model using DenseNet121 as the encoder.\n",
        "\n",
        "    Args:\n",
        "        input_size (tuple): Size of the input image.\n",
        "\n",
        "    Returns:\n",
        "        tf.keras.Model: U-Net model.\n",
        "    \"\"\"\n",
        "    inputs = Input(input_size)\n",
        "    encoder = DenseNet121(include_top=False, weights='imagenet', input_tensor=inputs)\n",
        "    skip1 = encoder.get_layer(\"conv1/relu\").output  # 128x128\n",
        "    skip2 = encoder.get_layer(\"pool2_relu\").output  # 64x64\n",
        "    skip3 = encoder.get_layer(\"pool3_relu\").output  # 32x32\n",
        "    skip4 = encoder.get_layer(\"pool4_relu\").output  # 16x16\n",
        "    bottleneck = encoder.get_layer(\"relu\").output  # 8x8\n",
        "\n",
        "    up1 = UpSampling2D((2, 2))(bottleneck)\n",
        "    up1 = Conv2D(512, (3, 3), padding=\"same\", activation=\"relu\")(up1)\n",
        "    up1 = concatenate([up1, skip4])\n",
        "\n",
        "    up2 = UpSampling2D((2, 2))(up1)\n",
        "    up2 = Conv2D(256, (3, 3), padding=\"same\", activation=\"relu\")(up2)\n",
        "    up2 = concatenate([up2, skip3])\n",
        "\n",
        "    up3 = UpSampling2D((2, 2))(up2)\n",
        "    up3 = Conv2D(128, (3, 3), padding=\"same\", activation=\"relu\")(up3)\n",
        "    up3 = concatenate([up3, skip2])\n",
        "\n",
        "    up4 = UpSampling2D((2, 2))(up3)\n",
        "    up4 = Conv2D(64, (3, 3), padding=\"same\", activation=\"relu\")(up4)\n",
        "    up4 = concatenate([up4, skip1])\n",
        "\n",
        "    up5 = UpSampling2D((2, 2))(up4)\n",
        "    up5 = Conv2D(32, (3, 3), padding=\"same\", activation=\"relu\")(up5)\n",
        "\n",
        "    outputs = Conv2D(1, (1, 1), activation='sigmoid')(up5)\n",
        "    model = Model(inputs=inputs, outputs=outputs)\n",
        "    return model"
      ],
      "metadata": {
        "id": "p_4np9qGBptd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to train the model\n",
        "def train(train_dataset, val_dataset, epochs=25):\n",
        "    \"\"\"\n",
        "    Train the U-Net model.\n",
        "\n",
        "    Args:\n",
        "        train_dataset (tf.data.Dataset): Training dataset.\n",
        "        val_dataset (tf.data.Dataset): Validation dataset.\n",
        "        epochs (int): Number of epochs to train the model.\n",
        "\n",
        "    Returns:\n",
        "        tf.keras.Model: Trained U-Net model.\n",
        "        tf.keras.callbacks.History: History object containing training history.\n",
        "    \"\"\"\n",
        "    model = unet_model()\n",
        "    model.compile(optimizer='adam', loss='binary_crossentropy', metrics=['accuracy'])\n",
        "    history = model.fit(train_dataset, epochs=epochs, validation_data=val_dataset)\n",
        "\n",
        "    # Save the model\n",
        "    model.save('/content/drive/MyDrive/Road-Segmentation-Comp/unet_model.h5')\n",
        "\n",
        "    return model, history\n",
        "\n",
        "# Train the model\n",
        "model, history = train(train_dataset, val_dataset)\n"
      ],
      "metadata": {
        "id": "4kK1DU6-BsS0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Plot training and validation metrics\n",
        "def plot_metrics(history):\n",
        "    \"\"\"\n",
        "    Plot the training and validation metrics.\n",
        "\n",
        "    Args:\n",
        "        history (tf.keras.callbacks.History): History object containing training history.\n",
        "    \"\"\"\n",
        "    train_loss = history.history['loss']\n",
        "    val_loss = history.history['val_loss']\n",
        "    train_accuracy = history.history['accuracy']\n",
        "    val_accuracy = history.history['val_accuracy']\n",
        "\n",
        "    plt.figure(figsize=(12, 5))\n",
        "\n",
        "    plt.subplot(1, 2, 1)\n",
        "    plt.plot(train_loss, label='Training Loss')\n",
        "    plt.plot(val_loss, label='Validation Loss')\n",
        "    plt.title('Training and Validation Loss')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Loss')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.subplot(1, 2, 2)\n",
        "    plt.plot(train_accuracy, label='Training Accuracy')\n",
        "    plt.plot(val_accuracy, label='Validation Accuracy')\n",
        "    plt.title('Training and Validation Accuracy')\n",
        "    plt.xlabel('Epochs')\n",
        "    plt.ylabel('Accuracy')\n",
        "    plt.legend()\n",
        "\n",
        "    plt.show()\n",
        "\n",
        "# Plot the metrics\n",
        "plot_metrics(history)\n"
      ],
      "metadata": {
        "id": "U-2FJYa-BvFM"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "\n",
        "# Function to evaluate the model and make predictions\n",
        "def predict_and_evaluate(model, val_dataset):\n",
        "    \"\"\"\n",
        "    Evaluate the model and make predictions on the validation dataset.\n",
        "\n",
        "    Args:\n",
        "        model (tf.keras.Model): Trained U-Net model.\n",
        "        val_dataset (tf.data.Dataset): Validation dataset.\n",
        "\n",
        "    Returns:\n",
        "        float: F1 score on the validation dataset.\n",
        "    \"\"\"\n",
        "    y_true, y_pred = [], []\n",
        "\n",
        "    for images, masks in val_dataset:\n",
        "        predictions = model.predict(images)\n",
        "        predictions = (predictions > 0.5).astype(np.uint8)  # Threshold predictions to get binary masks\n",
        "\n",
        "        y_true.extend((masks.numpy() > 0.5).astype(np.uint8).flatten())  # Binarize y_true\n",
        "        y_pred.extend(predictions.flatten())\n",
        "\n",
        "    f1 = f1_score(y_true, y_pred)\n",
        "    print(\"F1 Score: \", f1)\n",
        "\n",
        "    # Display 3 random images, true masks, and predicted masks\n",
        "    val_images, val_masks = [], []\n",
        "    for images, masks in val_dataset:\n",
        "        val_images.extend(images.numpy())\n",
        "        val_masks.extend(masks.numpy())\n",
        "\n",
        "    indices = random.sample(range(len(val_images)), 3)\n",
        "    predicted_masks = model.predict(np.array([val_images[i] for i in indices]))\n",
        "    predicted_masks = (predicted_masks > 0.5).astype(np.uint8)\n",
        "\n",
        "    for i, idx in enumerate(indices):\n",
        "        plt.figure(figsize=(12, 4))\n",
        "\n",
        "        plt.subplot(1, 3, 1)\n",
        "        plt.imshow(val_images[idx])\n",
        "        plt.title('Original Image')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 2)\n",
        "        plt.imshow(val_masks[idx].squeeze(), cmap='gray')\n",
        "        plt.title('True Mask')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.subplot(1, 3, 3)\n",
        "        plt.imshow(predicted_masks[i].squeeze(), cmap='gray')\n",
        "        plt.title('Predicted Mask')\n",
        "        plt.axis('off')\n",
        "\n",
        "        plt.show()\n",
        "\n",
        "    return f1\n",
        "\n",
        "# Evaluate the model and make predictions\n",
        "f1 = predict_and_evaluate(model, val_dataset)"
      ],
      "metadata": {
        "id": "7zsWFupfBxar"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}